Args in experiment:
Namespace(is_training=1, model_id='ETTh2_96_336', model='iMamba', data='ETTh2', root_path='./dataset/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, enc_in=7, dec_in=7, c_out=7, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=3e-05, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, d_state=2)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_336_iMamba_ETTh2_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.4120492
	speed: 0.0185s/iter; left time: 45.5566s
	iters: 200, epoch: 1 | loss: 0.5889857
	speed: 0.0129s/iter; left time: 30.5703s
Epoch: 1 cost time: 3.8421266078948975
Epoch: 1, Steps: 256 | Train Loss: 0.7443980 Vali Loss: 0.4014496 Test Loss: 0.4599498
Validation loss decreased (inf --> 0.401450).  Saving model ...
Updating learning rate to 3e-05
	iters: 100, epoch: 2 | loss: 0.4133719
	speed: 0.1095s/iter; left time: 241.5041s
	iters: 200, epoch: 2 | loss: 1.0536911
	speed: 0.0122s/iter; left time: 25.6029s
Epoch: 2 cost time: 3.2577974796295166
Epoch: 2, Steps: 256 | Train Loss: 0.6889443 Vali Loss: 0.3789532 Test Loss: 0.4384542
Validation loss decreased (0.401450 --> 0.378953).  Saving model ...
Updating learning rate to 1.5e-05
	iters: 100, epoch: 3 | loss: 0.4564142
	speed: 0.1237s/iter; left time: 241.1135s
	iters: 200, epoch: 3 | loss: 1.0990077
	speed: 0.0173s/iter; left time: 31.9719s
Epoch: 3 cost time: 4.329669952392578
Epoch: 3, Steps: 256 | Train Loss: 0.6625403 Vali Loss: 0.3736008 Test Loss: 0.4324712
Validation loss decreased (0.378953 --> 0.373601).  Saving model ...
Updating learning rate to 7.5e-06
	iters: 100, epoch: 4 | loss: 0.3896449
	speed: 0.1274s/iter; left time: 215.7016s
	iters: 200, epoch: 4 | loss: 1.1627001
	speed: 0.0186s/iter; left time: 29.6318s
Epoch: 4 cost time: 4.709712743759155
Epoch: 4, Steps: 256 | Train Loss: 0.6497830 Vali Loss: 0.3727645 Test Loss: 0.4300827
Validation loss decreased (0.373601 --> 0.372765).  Saving model ...
Updating learning rate to 3.75e-06
	iters: 100, epoch: 5 | loss: 0.7245300
	speed: 0.1023s/iter; left time: 147.0734s
	iters: 200, epoch: 5 | loss: 0.6317027
	speed: 0.0117s/iter; left time: 15.6901s
Epoch: 5 cost time: 3.310317039489746
Epoch: 5, Steps: 256 | Train Loss: 0.6432990 Vali Loss: 0.3725908 Test Loss: 0.4296247
Validation loss decreased (0.372765 --> 0.372591).  Saving model ...
Updating learning rate to 1.875e-06
	iters: 100, epoch: 6 | loss: 0.5071770
	speed: 0.1145s/iter; left time: 135.2054s
	iters: 200, epoch: 6 | loss: 0.8933448
	speed: 0.0119s/iter; left time: 12.9080s
Epoch: 6 cost time: 3.154754638671875
Epoch: 6, Steps: 256 | Train Loss: 0.6397253 Vali Loss: 0.3724594 Test Loss: 0.4290305
Validation loss decreased (0.372591 --> 0.372459).  Saving model ...
Updating learning rate to 9.375e-07
	iters: 100, epoch: 7 | loss: 0.6635221
	speed: 0.1167s/iter; left time: 107.9173s
	iters: 200, epoch: 7 | loss: 0.6002830
	speed: 0.0119s/iter; left time: 9.7952s
Epoch: 7 cost time: 3.1449925899505615
Epoch: 7, Steps: 256 | Train Loss: 0.6377738 Vali Loss: 0.3713288 Test Loss: 0.4286909
Validation loss decreased (0.372459 --> 0.371329).  Saving model ...
Updating learning rate to 4.6875e-07
	iters: 100, epoch: 8 | loss: 0.6432333
	speed: 0.1110s/iter; left time: 74.2555s
	iters: 200, epoch: 8 | loss: 0.5711567
	speed: 0.0116s/iter; left time: 6.6100s
Epoch: 8 cost time: 2.955961227416992
Epoch: 8, Steps: 256 | Train Loss: 0.6366123 Vali Loss: 0.3720326 Test Loss: 0.4286406
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.34375e-07
	iters: 100, epoch: 9 | loss: 0.5944648
	speed: 0.1149s/iter; left time: 47.4580s
	iters: 200, epoch: 9 | loss: 0.7240280
	speed: 0.0120s/iter; left time: 3.7506s
Epoch: 9 cost time: 3.3901445865631104
Epoch: 9, Steps: 256 | Train Loss: 0.6368220 Vali Loss: 0.3718203 Test Loss: 0.4286034
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.171875e-07
	iters: 100, epoch: 10 | loss: 0.7880974
	speed: 0.1185s/iter; left time: 18.6018s
	iters: 200, epoch: 10 | loss: 0.4893187
	speed: 0.0177s/iter; left time: 1.0071s
Epoch: 10 cost time: 4.105653762817383
Epoch: 10, Steps: 256 | Train Loss: 0.6374853 Vali Loss: 0.3713443 Test Loss: 0.4285995
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_336_iMamba_ETTh2_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 1, 336, 7) (2545, 1, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.42869091033935547, mae:0.4363773465156555
