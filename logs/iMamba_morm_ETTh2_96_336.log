Args in experiment:
Namespace(is_training=1, model_id='ETTh2_96_336', model='iMamba', data='ETTh2', root_path='./dataset/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, enc_in=7, dec_in=7, c_out=7, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=3e-05, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, d_state=2)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_336_iMamba_ETTh2_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.9413087
	speed: 0.0355s/iter; left time: 87.2764s
	iters: 200, epoch: 1 | loss: 0.5469965
	speed: 0.0211s/iter; left time: 49.7894s
Epoch: 1 cost time: 6.769750595092773
Epoch: 1, Steps: 256 | Train Loss: 0.7427544 Vali Loss: 0.4037943 Test Loss: 0.4610397
Validation loss decreased (inf --> 0.403794).  Saving model ...
Updating learning rate to 3e-05
	iters: 100, epoch: 2 | loss: 0.9625273
	speed: 0.3907s/iter; left time: 861.5858s
	iters: 200, epoch: 2 | loss: 0.5899831
	speed: 0.0299s/iter; left time: 62.8772s
Epoch: 2 cost time: 7.566702842712402
Epoch: 2, Steps: 256 | Train Loss: 0.6954304 Vali Loss: 0.3814466 Test Loss: 0.4433750
Validation loss decreased (0.403794 --> 0.381447).  Saving model ...
Updating learning rate to 1.5e-05
	iters: 100, epoch: 3 | loss: 0.3573915
	speed: 0.3858s/iter; left time: 751.9799s
	iters: 200, epoch: 3 | loss: 0.5089602
	speed: 0.0270s/iter; left time: 49.9676s
Epoch: 3 cost time: 6.9132256507873535
Epoch: 3, Steps: 256 | Train Loss: 0.6757693 Vali Loss: 0.3763227 Test Loss: 0.4366209
Validation loss decreased (0.381447 --> 0.376323).  Saving model ...
Updating learning rate to 7.5e-06
	iters: 100, epoch: 4 | loss: 0.5422126
	speed: 0.3825s/iter; left time: 647.5284s
	iters: 200, epoch: 4 | loss: 0.6863604
	speed: 0.0198s/iter; left time: 31.5351s
Epoch: 4 cost time: 5.372617483139038
Epoch: 4, Steps: 256 | Train Loss: 0.6684203 Vali Loss: 0.3743282 Test Loss: 0.4342167
Validation loss decreased (0.376323 --> 0.374328).  Saving model ...
Updating learning rate to 3.75e-06
	iters: 100, epoch: 5 | loss: 0.6148486
	speed: 0.3831s/iter; left time: 550.4691s
	iters: 200, epoch: 5 | loss: 0.6316288
	speed: 0.0168s/iter; left time: 22.4984s
Epoch: 5 cost time: 4.711613655090332
Epoch: 5, Steps: 256 | Train Loss: 0.6651472 Vali Loss: 0.3731718 Test Loss: 0.4333891
Validation loss decreased (0.374328 --> 0.373172).  Saving model ...
Updating learning rate to 1.875e-06
	iters: 100, epoch: 6 | loss: 0.6194749
	speed: 0.3652s/iter; left time: 431.3061s
	iters: 200, epoch: 6 | loss: 0.7014421
	speed: 0.0263s/iter; left time: 28.4394s
Epoch: 6 cost time: 6.086115837097168
Epoch: 6, Steps: 256 | Train Loss: 0.6636421 Vali Loss: 0.3730408 Test Loss: 0.4329273
Validation loss decreased (0.373172 --> 0.373041).  Saving model ...
Updating learning rate to 9.375e-07
	iters: 100, epoch: 7 | loss: 0.8055567
	speed: 0.3888s/iter; left time: 359.6763s
	iters: 200, epoch: 7 | loss: 0.4587624
	speed: 0.0194s/iter; left time: 16.0401s
Epoch: 7 cost time: 5.2361159324646
Epoch: 7, Steps: 256 | Train Loss: 0.6624050 Vali Loss: 0.3727517 Test Loss: 0.4326980
Validation loss decreased (0.373041 --> 0.372752).  Saving model ...
Updating learning rate to 4.6875e-07
	iters: 100, epoch: 8 | loss: 0.7039393
	speed: 0.3795s/iter; left time: 253.9115s
	iters: 200, epoch: 8 | loss: 0.7923002
	speed: 0.0219s/iter; left time: 12.4425s
Epoch: 8 cost time: 5.822829008102417
Epoch: 8, Steps: 256 | Train Loss: 0.6633073 Vali Loss: 0.3727157 Test Loss: 0.4325924
Validation loss decreased (0.372752 --> 0.372716).  Saving model ...
Updating learning rate to 2.34375e-07
	iters: 100, epoch: 9 | loss: 0.9829072
	speed: 0.3883s/iter; left time: 160.3608s
	iters: 200, epoch: 9 | loss: 0.7366594
	speed: 0.0195s/iter; left time: 6.1053s
Epoch: 9 cost time: 5.561840772628784
Epoch: 9, Steps: 256 | Train Loss: 0.6627061 Vali Loss: 0.3728214 Test Loss: 0.4325370
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.171875e-07
	iters: 100, epoch: 10 | loss: 0.5458525
	speed: 0.3822s/iter; left time: 60.0013s
	iters: 200, epoch: 10 | loss: 0.8546607
	speed: 0.0209s/iter; left time: 1.1919s
Epoch: 10 cost time: 5.418692350387573
Epoch: 10, Steps: 256 | Train Loss: 0.6616610 Vali Loss: 0.3727590 Test Loss: 0.4325149
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.859375e-08
>>>>>>>testing : ETTh2_96_336_iMamba_ETTh2_M_ft96_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 1, 336, 7) (2545, 1, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.43259233236312866, mae:0.438907653093338
