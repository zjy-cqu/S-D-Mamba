Args in experiment:
Namespace(is_training=1, model_id='ETTh2_96_96', model='iMamba', data='ETTh2', root_path='./dataset/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=4e-05, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, d_state=2)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_96_iMamba_ETTh2_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2698480
	speed: 0.0276s/iter; left time: 70.2262s
	iters: 200, epoch: 1 | loss: 0.4413650
	speed: 0.0201s/iter; left time: 48.9663s
Epoch: 1 cost time: 6.108644008636475
Epoch: 1, Steps: 264 | Train Loss: 0.5123352 Vali Loss: 0.2394277 Test Loss: 0.3237340
Validation loss decreased (inf --> 0.239428).  Saving model ...
Updating learning rate to 4e-05
	iters: 100, epoch: 2 | loss: 0.2204517
	speed: 0.4126s/iter; left time: 939.4650s
	iters: 200, epoch: 2 | loss: 0.4586313
	speed: 0.0225s/iter; left time: 48.8801s
Epoch: 2 cost time: 6.105327129364014
Epoch: 2, Steps: 264 | Train Loss: 0.4550005 Vali Loss: 0.2264490 Test Loss: 0.3074987
Validation loss decreased (0.239428 --> 0.226449).  Saving model ...
Updating learning rate to 2e-05
	iters: 100, epoch: 3 | loss: 0.3877410
	speed: 0.4246s/iter; left time: 854.7569s
	iters: 200, epoch: 3 | loss: 0.3572825
	speed: 0.0217s/iter; left time: 41.4815s
Epoch: 3 cost time: 5.864560604095459
Epoch: 3, Steps: 264 | Train Loss: 0.4360644 Vali Loss: 0.2236741 Test Loss: 0.3038730
Validation loss decreased (0.226449 --> 0.223674).  Saving model ...
Updating learning rate to 1e-05
	iters: 100, epoch: 4 | loss: 0.3867785
	speed: 0.4102s/iter; left time: 717.4615s
	iters: 200, epoch: 4 | loss: 0.4416793
	speed: 0.0229s/iter; left time: 37.8091s
Epoch: 4 cost time: 6.0411176681518555
Epoch: 4, Steps: 264 | Train Loss: 0.4273533 Vali Loss: 0.2230472 Test Loss: 0.3024436
Validation loss decreased (0.223674 --> 0.223047).  Saving model ...
Updating learning rate to 5e-06
	iters: 100, epoch: 5 | loss: 0.4171542
	speed: 0.4088s/iter; left time: 607.0371s
	iters: 200, epoch: 5 | loss: 0.5349631
	speed: 0.0198s/iter; left time: 27.3819s
Epoch: 5 cost time: 5.3618693351745605
Epoch: 5, Steps: 264 | Train Loss: 0.4229993 Vali Loss: 0.2228615 Test Loss: 0.3017583
Validation loss decreased (0.223047 --> 0.222861).  Saving model ...
Updating learning rate to 2.5e-06
	iters: 100, epoch: 6 | loss: 0.5256435
	speed: 0.4075s/iter; left time: 497.5204s
	iters: 200, epoch: 6 | loss: 0.2727047
	speed: 0.0200s/iter; left time: 22.4315s
Epoch: 6 cost time: 5.477762460708618
Epoch: 6, Steps: 264 | Train Loss: 0.4203849 Vali Loss: 0.2226973 Test Loss: 0.3014760
Validation loss decreased (0.222861 --> 0.222697).  Saving model ...
Updating learning rate to 1.25e-06
	iters: 100, epoch: 7 | loss: 0.4127095
	speed: 0.4088s/iter; left time: 391.2659s
	iters: 200, epoch: 7 | loss: 0.3514279
	speed: 0.0224s/iter; left time: 19.1784s
Epoch: 7 cost time: 5.817928075790405
Epoch: 7, Steps: 264 | Train Loss: 0.4190175 Vali Loss: 0.2226232 Test Loss: 0.3013718
Validation loss decreased (0.222697 --> 0.222623).  Saving model ...
Updating learning rate to 6.25e-07
	iters: 100, epoch: 8 | loss: 0.2106771
	speed: 0.4119s/iter; left time: 285.4269s
	iters: 200, epoch: 8 | loss: 0.3684696
	speed: 0.0188s/iter; left time: 11.1285s
Epoch: 8 cost time: 5.2340075969696045
Epoch: 8, Steps: 264 | Train Loss: 0.4189450 Vali Loss: 0.2226160 Test Loss: 0.3013005
Validation loss decreased (0.222623 --> 0.222616).  Saving model ...
Updating learning rate to 3.125e-07
	iters: 100, epoch: 9 | loss: 0.4414594
	speed: 0.4007s/iter; left time: 171.9011s
	iters: 200, epoch: 9 | loss: 0.2225976
	speed: 0.0179s/iter; left time: 5.8799s
Epoch: 9 cost time: 4.621598958969116
Epoch: 9, Steps: 264 | Train Loss: 0.4185375 Vali Loss: 0.2226579 Test Loss: 0.3012863
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-07
	iters: 100, epoch: 10 | loss: 0.2659639
	speed: 0.4384s/iter; left time: 72.3352s
	iters: 200, epoch: 10 | loss: 0.5065675
	speed: 0.0214s/iter; left time: 1.3880s
Epoch: 10 cost time: 5.887333154678345
Epoch: 10, Steps: 264 | Train Loss: 0.4181255 Vali Loss: 0.2226327 Test Loss: 0.3012675
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-08
>>>>>>>testing : ETTh2_96_96_iMamba_ETTh2_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 1, 96, 7) (2785, 1, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.30130061507225037, mae:0.3525412976741791
