Args in experiment:
Namespace(is_training=1, model_id='ETTh1_96_96', model='iMamba', data='ETTh1', root_path='./dataset/ETT-small/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=7e-05, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, d_state=2)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_96_iMamba_ETTh1_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.4699445
	speed: 0.0212s/iter; left time: 53.9474s
	iters: 200, epoch: 1 | loss: 0.4076977
	speed: 0.0158s/iter; left time: 38.5444s
Epoch: 1 cost time: 4.732824087142944
Epoch: 1, Steps: 264 | Train Loss: 0.4637702 Vali Loss: 0.7354336 Test Loss: 0.4202890
Validation loss decreased (inf --> 0.735434).  Saving model ...
Updating learning rate to 7e-05
	iters: 100, epoch: 2 | loss: 0.4053328
	speed: 0.1296s/iter; left time: 295.1775s
	iters: 200, epoch: 2 | loss: 0.3686557
	speed: 0.0154s/iter; left time: 33.6306s
Epoch: 2 cost time: 4.2402637004852295
Epoch: 2, Steps: 264 | Train Loss: 0.3802137 Vali Loss: 0.7013440 Test Loss: 0.3987462
Validation loss decreased (0.735434 --> 0.701344).  Saving model ...
Updating learning rate to 3.5e-05
	iters: 100, epoch: 3 | loss: 0.3432590
	speed: 0.1294s/iter; left time: 260.4265s
	iters: 200, epoch: 3 | loss: 0.4354462
	speed: 0.0156s/iter; left time: 29.9350s
Epoch: 3 cost time: 4.2249956130981445
Epoch: 3, Steps: 264 | Train Loss: 0.3586643 Vali Loss: 0.6900936 Test Loss: 0.3962494
Validation loss decreased (0.701344 --> 0.690094).  Saving model ...
Updating learning rate to 1.75e-05
	iters: 100, epoch: 4 | loss: 0.3869312
	speed: 0.1212s/iter; left time: 211.9048s
	iters: 200, epoch: 4 | loss: 0.3162701
	speed: 0.0148s/iter; left time: 24.4849s
Epoch: 4 cost time: 4.023657321929932
Epoch: 4, Steps: 264 | Train Loss: 0.3513712 Vali Loss: 0.6868492 Test Loss: 0.3930804
Validation loss decreased (0.690094 --> 0.686849).  Saving model ...
Updating learning rate to 8.75e-06
	iters: 100, epoch: 5 | loss: 0.2969673
	speed: 0.1259s/iter; left time: 186.9645s
	iters: 200, epoch: 5 | loss: 0.3385162
	speed: 0.0155s/iter; left time: 21.4455s
Epoch: 5 cost time: 3.936086654663086
Epoch: 5, Steps: 264 | Train Loss: 0.3480472 Vali Loss: 0.6865973 Test Loss: 0.3931022
Validation loss decreased (0.686849 --> 0.686597).  Saving model ...
Updating learning rate to 4.375e-06
	iters: 100, epoch: 6 | loss: 0.3193225
	speed: 0.1213s/iter; left time: 148.1206s
	iters: 200, epoch: 6 | loss: 0.3761643
	speed: 0.0152s/iter; left time: 17.0333s
Epoch: 6 cost time: 4.062863111495972
Epoch: 6, Steps: 264 | Train Loss: 0.3460132 Vali Loss: 0.6864948 Test Loss: 0.3929410
Validation loss decreased (0.686597 --> 0.686495).  Saving model ...
Updating learning rate to 2.1875e-06
	iters: 100, epoch: 7 | loss: 0.3136867
	speed: 0.1230s/iter; left time: 117.7035s
	iters: 200, epoch: 7 | loss: 0.3533568
	speed: 0.0138s/iter; left time: 11.8263s
Epoch: 7 cost time: 3.774196147918701
Epoch: 7, Steps: 264 | Train Loss: 0.3454833 Vali Loss: 0.6863794 Test Loss: 0.3934956
Validation loss decreased (0.686495 --> 0.686379).  Saving model ...
Updating learning rate to 1.09375e-06
	iters: 100, epoch: 8 | loss: 0.3878414
	speed: 0.1167s/iter; left time: 80.9064s
	iters: 200, epoch: 8 | loss: 0.4237178
	speed: 0.0154s/iter; left time: 9.1193s
Epoch: 8 cost time: 3.996051549911499
Epoch: 8, Steps: 264 | Train Loss: 0.3448710 Vali Loss: 0.6858689 Test Loss: 0.3934088
Validation loss decreased (0.686379 --> 0.685869).  Saving model ...
Updating learning rate to 5.46875e-07
	iters: 100, epoch: 9 | loss: 0.3297148
	speed: 0.1246s/iter; left time: 53.4502s
	iters: 200, epoch: 9 | loss: 0.3357810
	speed: 0.0156s/iter; left time: 5.1251s
Epoch: 9 cost time: 4.206582307815552
Epoch: 9, Steps: 264 | Train Loss: 0.3446460 Vali Loss: 0.6861709 Test Loss: 0.3934274
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.734375e-07
	iters: 100, epoch: 10 | loss: 0.3583094
	speed: 0.1261s/iter; left time: 20.8130s
	iters: 200, epoch: 10 | loss: 0.3976667
	speed: 0.0154s/iter; left time: 1.0025s
Epoch: 10 cost time: 4.191766262054443
Epoch: 10, Steps: 264 | Train Loss: 0.3449157 Vali Loss: 0.6862227 Test Loss: 0.3933984
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.3671875e-07
>>>>>>>testing : ETTh1_96_96_iMamba_ETTh1_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 1, 96, 7) (2785, 1, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3934089243412018, mae:0.41202232241630554
